# 2.3 Prospect theory

Prospect theory is a descriptive theory of the decisions people make when faced with a gamble. It is not a theory of *how* people make decisions, nor a theory of how they should make decisions.

You have covered prospect theory and its components in earlier units. Here is a recap.

## Reference dependence

> 1. You have not checked your share portfolio in a while. You expect it is worth around $40,000. Today when you check, it is worth \$30,000. Do you feel rich or poor?
>
> 2. You have not checked your share portfolio in a while. You expect it is worth around $20,000. Today when you check, it is worth \$30,000. Do you feel rich or poor?

People assess choices based on their reference point - where they currently are - as opposed to an overarching assessment of their position. Potential outcomes are coded as losses and gains relative to that reference point.

Reference points can be thought of a state to which you have become adapted.

## Loss aversion

> You are offered a gamble on the toss of a coin. If you flip a heads, you lose \$100. If you flip a tails, you win \$150. Do you accept the gamble?

Loss aversion is the concept that losses loom larger than gains. People feel a loss more strongly about a loss than they do an equivalent gain, so are often willing to reject gambles with a materially positive expected value.

Rejection of bets of this nature cannot easily be explained by risk aversion. As shown by Rabin (2000), rejection of bets over moderate stakes requires absurd rates of risk aversion. For instance, if a person who acts consistent with expected utility theory  always turns down a 50:50 bet to win $110 or lose \$100 whatever their initial level of wealth, they will also turn down a 50:50 bet to win \$1 billion, lose \$1,000.

## Reflection effect

Kahneman and Tversky (1984) reported the following experiment:

>Imagine that the U.S. is preparing for the outbreak of an unusual Asian disease, which is expected to kill 600 people. Two alternative programs to combat the disease have been proposed. Assume that the exact scientific estimates of the consequences of the pro-grams are as follows:
>
>If Program A is adopted, 200 people will be saved.
>
>If Program B is adopted, there is a one-third probability that 600 people will be saved and a two-thirds probability that no people will be saved.
>
>Which of the two programs would you favor?

In the initial experiment, 72% of participants chose option A.

But what if the experimental participants were presented with the following options?

>If Program C is adopted, 400 people will die.
>
>If Program D is adopted, there is a one-third probability that nobody will die and a two-thirds probability that 600 people will die.

Only 22% chose option C, despite it being equivalent to option A.

This phenomena is the reflection effect. When people make a risky choice related to gains, they are risk averse. They prefer a certain option with lower expected utility than the expected utility of the risky choice. When making a choice in the loss domain, they become risk seeking.

This phenomena might also be thought of as diminishing sensitivity to gains or losses in either direction. This contrasts with expected utility theory where the pain of losses increases as they grow in size.

The combination of loss aversion and the reflection effect results in the famous value function as in the following diagram:

![](/img/value_function.jpg)

[Chart on "Risk attitude and in EU and in PT" in sandpit]

## Probability weighting

> 1. You are granted entry into a prize draw that that gives you a 5% probability of gaining $10,000. How do you feel?
>
> 2. You are granted an additional entry into a prize draw for $10,000 that increases your probability of winning from 5% to 10%. How do you feel?
>
> 3. You are granted an additional entry into a prize draw for $10,000 that increases your probability of winning from 50% to 55%. How do you feel?
> 
> 4. You are granted an additional entry into a prize draw for $10,000 that increases your probability of winning from 95% to 100%. How do you feel?

From the perspective of expected utility theory, each of these four scenarios results in the same expected gain of $500. But they often feel markedly different.

People overweight small probabilities, giving them disproportionately more weight than they deserve. They also underweight large probabilities that fall short of certainty, giving them less weight than is justified. This results in the shifts in scenarios 1 and 4 above generally being received more gratefully than that in scenarios 2 and 3.

Kahneman (2011) calls the large psychological value of the change from 0 to 5% (or some other small probability) the *possibility effect*. Very unlikely but possibles outcomes are given more weight than similar increases in probability for events that are already possible.  He calls the large psychological value of the change to 100% the *certainty effect*. We will pay a lot more for certainty than near certainty.

This pattern of probability weighting can be seen in the following diagram, where the probability *p* on the x axis is mapped to a new probability weight on the *y* axis.

![](/img/probability_weighting.png)
Figure 1, Tversky and Kahneman (1992)

[Chart on "Overweighting of small probabilities 2" in sandpit]

## Fourfold pattern of risk attitudes

Prospect theory results in a four-fold pattern of risk attitudes, as shown in this table. For moderate to high probability gambles, the reflection effect dominates and people are risk averse in the domain of gains and risk seeking in the domain of losses.

But for low probability gambles, the probability weighting shifts the decision calculus. The possibility of a gain is overweighted, making the gamble attractive and inducing risk seeking behaviour. A similar effect occurs for a low probability of loss, with the overweighted probability making the potential loss less attractive, inducing risk averse behaviour.

||Gains|Losses|
|---|---|---|
|**High probability** (certainty effect)|Risk aversion|Risk seeking|
|**Low probability** (possibility effect|Rick seeking|Risk aversion|

## Optional reading

Rabin and Thaler (2001) "Anomalies: Risk Aversion", *Journal of Economic Perspectives*, 15(1), 219-232, https://doi.org/10.1257/jep.15.1.219 (For a readable presentation of Rabin's calibration theorem)

## References

Kahneman (2011) *Thinking, Fast and Slow*, Penguin Random House UK

Kahneman and Tversky (1984) "Choices, Values and Frames", *American Psychologist*, 39(4), 341-350, https://psycnet.apa.org/doi/10.1037/0003-066X.39.4.341

Kahneman and Tversky (1979) "Prospect Theory: An Analysis of Decision under Risk", *Econometrica*, 47(2), 263–291, https://doi.org/10.2307/1914185

Rabin (2000) "Risk Aversion and Expected‐utility Theory: A Calibration Theorem", *Econometrica*, 68(5), 1281-1292, https://doi.org/10.1111/1468-0262.00158

Tversky and Kahneman (1992) "Advances in prospect theory: Cumulative representation of uncertainty", *Journal of Risk and Uncertainty*, 5, 297-323, https://doi.org/10.1007/BF00122574